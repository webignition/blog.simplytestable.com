---
layout: default
title: "3 Non-Code Production Performance Improvements For Developers"
author:
    name: Jon Cram
    url: https://github.com/webignition
---

<div class="section">
    <p>
        Last night I gave a talk titled "3 Non-Code Production Improvements For Developers"
        at the January 2013 <a href="http://unifieddiff.co.uk/">Unified Diff</a> meetup.
    </p>
    <p>
        A big thanks to <a href="https://twitter.com/HandyBiteSize">@HandyBiteSize</a>,
        <a href="https://twitter.com/gavD_UK">@gavD_UK</a> and <a href="https://twitter.com/rodnaph">@rodnaph</a>
        for continuing to organise the events, as well as <a href="https://twitter.com/craigmarvelley">@craigmarvelley</a>
        for helping me get my laptop connected to the projector.
    </p>
    <p>
        Slides and my initial preparatory notes are available at <a href="https://github.com/webignition/udiff-jan-2013">https://github.com/webignition/udiff-jan-2013</a>.
    </p>
    <p>
        I'd like to cover here in written form the talk I gave and in the not-too-distant future I'll include the
        video of the talk itself.
    </p>
    <h3>
        How I Turned Broken Into Working Without Changing My Code
    </h3>
    <p>
        I subtitled the talk <em>How I turned broken into working without changing
        my code</em>.
    </p>
    <p>
        I added this to highlight that it is the environment under
        which your applications run that can determine, more than the application
        code itself, how well a service will perform.
    </p>
    <p>
        Following the public launch of Simply Testable in mid-October, I was
        facing <a href="/post-launch-post-mortem/">major capacity problems</a>
        that continually broke the service day after day.
    </p>
    <p>
        I fixed these problems without touching a line of code and the results were
        orders of magnitude greater than any code change. I should also have added
        that no hardware changed.
    </p>
    <h3>The Developer Problem-Solving Mindset</h3>
    <img src="http://cdn.memegenerator.net/instances/400x/33145530.jpg" alt="Code All The Things!" class="inline-illustration pull-left" />
    <p>
         You're a developer, you write code. You write code all day long.
    </p>
    <p>
        You write code to build solutions to problems.
    </p>
    <p>
        You modify code to fix problems with your solutions to problems.
    </p>
    <p>
        You use code to solve your problems.
    </p>
    <p>
        Particularly as a developer who normally works within an organisation,
        you tend to think only in terms of code when looking to fix problems
        with a system.
    </p>
    <p>
        You may not consider looking beyond the code as a means of addressing
        problems.
    </p>
    <h3>And Then It Was All Broken (The Problems I Faced)</h3>
    <p>
        Simply Testable was failing massively on a daily basis:
    </p>

    <ul>
        <li>
            <p>
                As few as 12 concurrent full-site tests caused CPU bottlenecks
            </p>
        </li>
        <li>
            <p>
                DB queries were 2 orders of magnitude slower
            </p>
        </li>
        <li>
            <p>
                MySQL reading/writing caused disk I/O bottlenecks
            </p>
        </li>
        <li>
            <p>
                Full-site tests took 10x as long to complete
            </p>
        </li>
        <li>
            <p>
                Apache timeouts caused arbitrary failures
            </p>
        </li>
        <li>
            <p>
                <a href="http://en.wikipedia.org/wiki/List_of_military_slang_terms#FUBAR">FUBAR</a> situations were frequent
            </p>
        </li>
    </ul>
    <p>
        I wasn't convinced that a move to more powerful hardware would resolve
        these problems, I wasn't convinced that my code was totally awful (merely
        the usual level of awful) and I wasn't convinced that the production hardware
        was incapable of handling the load it was under.
    </p>
    <p>
        I needed to look beyond the code to see what else I could change within
        the production environment to make things better.
    </p>
    <h3>
        1. Nginx + php-fpm instead of Apache + mod_php
    </h3>
    <p>
        Apache was using about 50% of all CPU resource all the time. This looked
        significant and so my first task was to address this.
    </p>
    <p>
        I'd heard that Nginx was less resource intensive than Apache. Since Apache
        was continually using such a large portion of available CPU resources it
        made sense to try it out. I assumed in the worst case it would no worse
        than using Apache.
    </p>
    <p>
        I did also consider <a href="http://www.lighttpd.net/">lighttpd</a> as it
        is also a lightweight web server. I chose Nginx as I found the documentation
        more clear and complete and found specific configuration examples relating
        to Symfony.
    </p>
    <p>
        I also had to switch to using <a href="http://php-fpm.org/">php-fpm</a>;
        Nginx serves only static content and can be configured to proxy off requests
        for non-static content to something else. The something else in this case
        was php-fpm which appears to be the de-facto standard PHP processes manager
        to use with Nginx.
    </p>
    <p>
        The outcome on the same server under the same load levels:
    </p>
    <p>
        Average continuous CPU usage under <strong>Apache + mod_php: 50%</strong>
    </p>
    <p>
        Average continuous CPU usage under <strong>Nginx + php-fpm: 4%</strong>
    </p>

    <p>
        After making this change, I wrote in detail about <a href="/switching-from-apache-to-nginx/">switching from Apache to Nginx</a>
        for Ubuntu servers.
    </p>

    <h3>2. MySQL loves RAM, give it lots lots</h3>
    <p>
        MySQL was using about 20% of CPU resource (prior to the above change)
        and, as mentioned, was reading and writing from the hard disk to such
        an extent that this was causing (or at least appeared to cause) disk I/O
        bottlenecks.
    </p>
    <p>
        On a production server with 16GB of RAM, you'd really want MySQL to be
        using as much of this as possible to both cache data, so as to reduce
        the frequency of disk I/O operations, and to cache query results, so as to
        reduce amount of CPU resource required for turning data into information.
    </p>
    <p>
        The default out-the-box MySQL configuration in this respect is awful.
        It makes no reasonable use of abundant RAM resources, will under any
        significant usage patterns spend far too much time reading and
        re-reading data from disk and will not bother to remember the results
        of common operations on data.
    </p>
    <p>
        If you're using MySQL and dealing with a non-trivial volume of data you
        should be using InnoDB tables. Let's just assume you are and not go off on
        a tangent.
    </p>
    <p>
        By far the single most important consideration for InnoDB performance is
        the size of the InnoDB buffer pool, the memory area where InnoDB caches
        table and index data.
    </p>
    <p>
        Unfortunately all relevant configuration options surrounding this fail to
        refer to the word 'memory' in any way making it far less obvious that this
        is where you should be looking if you want to use as much memory as possible
        to cache your data.
    </p>
    <p>
        The MySQL performance blog has a great article on
        <a href="http://www.mysqlperformanceblog.com/2007/11/03/choosing-innodb_buffer_pool_size/">choosing the correct InnoDB buffer pool size</a>.
        I chose 8GB which should result in MySQL using between 8GB and 16GB in which
        to cache table data and indexes.
    </p>
    <p>
        The outcome on the same server under the same load levels:
    </p>
    <p>
        MySQL <strong>out-the-box configuration: 20%</strong>
    </p>
    <p>
        MySQL <strong>'lots of ram' configuration: 4%</strong>
    </p>
    <h3>
        3. Use /run/shm for impermanent file storage
    </h3>
    <p>
        /run/shm, under Unbuntu and Debian distributions, is the pre-mounted
        path for a tmpfs filesystem.
    </p>
    <p>
        This acts like a ramdisk but without the downside of pre-allocating a
        portion of RAM to be used, instead scaling up or down the size of RAM used
        as needed.
    </p>
    <p>
        This makes writing to /run/shm as fast as writing to RAM, making it perfect
        for any file storage where files do not need to be kept around forever,
        such as session files or any operation where you temporarily need to store
        some data in a file.
    </p>
    <p>
        Even if you are not suffering from any disk I/O performance problems,
        shfiting all impermanent file storage to /run/shm still frees up hard
        disk I/O resources to anything else that actually needs it. You cannot lose.
    </p>
    <h3>Improvement By Numbers</h3>
    <p>
        I didn't record specific statistics with respect to performance regarding
        these changes as my focus at the time was purely on turning something
        quite broken into something that worked.
    </p>
    <p>
        I did, however, have a very good idea of how well the system was performing
        before and after from having investigated the cause of the problems I was
        facing.
    </p>
    <p>
        An approximate before and after in numbers:
    </p>

    <table class="table table-striped">
        <tr>
            <td>
                <!-- This cell intentionally left blank. Please move on, nothing to see here. -->
            </td>
            <td><strong>Before</strong></td>
            <td><strong>After</strong></td>
            <td><strong>Improvement</strong></td>
        </tr>
        <tr>
            <th>Concurrent tests</th>
            <td>12</td>
            <td>40</td>
            <td>3x</td>
        </tr>
        <tr>
            <th>Average CPU load</th>
            <td>30</td>
            <td>4</td>
            <td>7x</td>
        </tr>
        <tr>
            <th>Typical query time</th>
            <td>0.2 seconds</td>
            <td>0.004 seconds</td>
            <td>500x</td>
        </tr>
        <tr>
            <th>Complex query time</th>
            <td>1 second</td>
            <td>0.02 seconds</td>
            <td>50x</td>
        </tr>
        <tr>
            <th>FUBAR frequency</th>
            <td>daily</td>
            <td>infrequent</td>
            <td>brilliant</td>
        </tr>
    </table>

    <h3>Important Bits To Remember</h3>

    <h4>Do Not Use Apache In Production</h4>

    <p>
        Nginx performance will not be worse than that of Apache out the box. You
        have nothing to lose going with Nginx and lots to gain.
    </p>

    <p>
        As a side bonus, the "native" reverse proxying of Nginx is phenominal
        and the configuration language is a delight to work with.
    </p>

    <h4>
        Default MySQL configuration is attrocious
    </h4>

    <p>
        Set the innodb_buffer_pool_size configuration option to half your total RAM
        size and that's it. Don't waste time trying to configure the query cache,
        it's useless.
    </p>

    <h4>
       Use /run/shm
    </h4>

    <p>
        It makes impermanent disk I/O performance a non-issue.
    </p>

</div>